{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['builtins',\n",
       " 'builtins',\n",
       " 'tensorflow',\n",
       " '1.13.1',\n",
       " 'keras',\n",
       " '2.2.4',\n",
       " 'matplotlib.pyplot',\n",
       " 'numpy',\n",
       " '1.16.5',\n",
       " 'pandas',\n",
       " '0.25.1',\n",
       " 'os',\n",
       " 'types',\n",
       " 'matplotlib',\n",
       " '3.1.1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types\n",
    "import matplotlib\n",
    "def imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            yield val.__name__\n",
    "            try:\n",
    "                yield val.__version__\n",
    "            except:\n",
    "                pass\n",
    "list(imports())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gobal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed for our Hot Dog & Pizza classes\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Class names\n",
    "HOT_DOG_CLASS_NAME = \"hot_dog\"\n",
    "PIZZA_CLASS_NAME = \"pizza\"\n",
    "\n",
    "# Classification type\n",
    "CLASSIFICATION_TYPE = 'binary'\n",
    "\n",
    "# Fixed for Hot Dog & Pizza color images\n",
    "CHANNELS = 3\n",
    "\n",
    "# AlexNet specific input image size\n",
    "IMAGE_RESIZE = 227\n",
    "\n",
    "# Padding strategy to keep the same image size\n",
    "SAME_PADDING = 'same'\n",
    "\n",
    "# Padding strategy with right and bottom crop\n",
    "VALID_PADDING = 'valid'\n",
    "\n",
    "# Pooling strategy\n",
    "RESNET50_POOLING_AVERAGE = 'avg'\n",
    "\n",
    "# Activation functions\n",
    "CONVOLUTIONAL_LAYER_ACTIVATION = 'relu'\n",
    "DENSE_LAYER_ACTIVATION = 'sigmoid'\n",
    "\n",
    "# Used to evaluate the error\n",
    "OBJECTIVE_FUNCTION = 'binary_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 5\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# Batch sizes for training and validation\n",
    "BATCH_SIZE_TRAINING = 128\n",
    "BATCH_SIZE_VALIDATION = 64\n",
    "\n",
    "# Steps for each epoch\n",
    "STEPS_PER_EPOCH_TRAINING = 1500 / BATCH_SIZE_TRAINING\n",
    "STEPS_PER_EPOCH_VALIDATION = 300 / BATCH_SIZE_VALIDATION\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction\n",
    "BATCH_SIZE_TESTING = 1\n",
    "\n",
    "# Work directory to save the checkpoints\n",
    "WORK_FOLDER = 'working'\n",
    "\n",
    "# Checkpoint file name\n",
    "CHECKPOINT_FILE = 'best.hdf5'\n",
    "\n",
    "# Automatic save and replace mode of the weights\n",
    "MODEL_CHECKPOINT_MODE = 'auto'\n",
    "\n",
    "# The metrics that we want to monitor\n",
    "LOSS_MONITOR = 'val_loss'\n",
    "\n",
    "# Weights file name\n",
    "WEIGHTS_FILE = 'best_weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base folder path for the Hot Dog & Pizza classification images\n",
    "BASE_FOLDER_PATH = os.path.join('datasets', 'hotdog_pizza')\n",
    "\n",
    "# The path to the training images\n",
    "TRAIN_FOLDER_PATH = os.path.join(BASE_FOLDER_PATH, 'train')\n",
    "\n",
    "# The path to the validation images\n",
    "VALIDATION_FOLDER_PATH = os.path.join(BASE_FOLDER_PATH, 'valid')\n",
    "\n",
    "# The path to the test images\n",
    "TEST_FOLDER_PATH = os.path.join(BASE_FOLDER_PATH, 'test')\n",
    "\n",
    "# Checkpoint file path\n",
    "CHECKPOINT_FILE_PATH = os.path.join(WORK_FOLDER, CHECKPOINT_FILE)\n",
    "\n",
    "# Weights file path\n",
    "WEIGHTS_FILE_PATH = os.path.join(WORK_FOLDER, WEIGHTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to load and resize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = lambda image_name: np.asarray(load_img(image_name, target_size=(IMAGE_RESIZE, IMAGE_RESIZE)))\n",
    "\n",
    "def read_images(image_path):\n",
    "    image_names = os.listdir(image_path)\n",
    "    image_paths = [os.path.join(image_path, image_name) for image_name in image_names]\n",
    "    images = np.array([read(image_path) for image_path in image_paths], dtype='uint8')\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to show the classification results and the confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, image):\n",
    "    scaled_image = image/255.\n",
    "    y_pred = model.predict_classes([[scaled_image]])\n",
    "    confidence = model.predict([[scaled_image]])\n",
    "    print(\"Predicted class:\")\n",
    "    \n",
    "    if y_pred[0] == 1:\n",
    "        print(PIZZA_CLASS_NAME)\n",
    "    else:\n",
    "        print(HOT_DOG_CLASS_NAME)\n",
    "    \n",
    "    print(y_pred[0][0])\n",
    "    \n",
    "    print(\"Confidence:\")\n",
    "    print(confidence[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to visualize the training process history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(fit_history):\n",
    "    training_accuracy_key = 'acc'\n",
    "    training_loss_key = 'loss'\n",
    "    \n",
    "    test_accuracy_key = 'val_acc'\n",
    "    test_loss_key = 'val_loss'\n",
    "    \n",
    "    diagrams_x_label = 'epoch'\n",
    "    \n",
    "    accuracy_diagram_title = 'model accuracy'\n",
    "    accuracy_diagram_y_label = 'accuracy'\n",
    "    \n",
    "    loss_diagram_title = 'model loss'\n",
    "    loss_diagram_y_label = 'loss'\n",
    "    \n",
    "    legend_labels = ['train', 'test']\n",
    "    legend_position = 'upper left'\n",
    "    \n",
    "    # list all data in history\n",
    "    print(fit_history.history.keys())\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(fit_history.history[training_accuracy_key])\n",
    "    plt.plot(fit_history.history[test_accuracy_key])\n",
    "    plt.title(accuracy_diagram_title)\n",
    "    plt.ylabel(accuracy_diagram_y_label)\n",
    "    plt.xlabel(diagrams_x_label)\n",
    "    plt.legend(legend_labels, loc=legend_position)\n",
    "    plt.show()\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.plot(fit_history.history[training_loss_key])\n",
    "    plt.plot(fit_history.history[test_loss_key])\n",
    "    plt.title(loss_diagram_title)\n",
    "    plt.ylabel(loss_diagram_y_label)\n",
    "    plt.xlabel(diagrams_x_label)\n",
    "    plt.legend(legend_labels, loc=legend_position)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
